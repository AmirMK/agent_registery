{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ba7cb-b540-43fe-b887-63d5cdd2f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai import agent_engines\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Constants & Display Messages\n",
    "# -----------------------------\n",
    "ENGINE_RESOURCE = \"projects/641879769713/locations/us-central1/reasoningEngines/4165059997178265600\"\n",
    "DEFAULT_USER = \"amirmeimand\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Initialize the Vertex AI Agent Engine and create a session only once.\n",
    "Returns (adk_app, user, session_id)\n",
    "\"\"\"\n",
    "adk_app = agent_engines.get(ENGINE_RESOURCE)\n",
    "user = DEFAULT_USER\n",
    "\n",
    "# Create a session (idempotent enough for our needs); then reuse the latest.\n",
    "adk_app.create_session(user_id=user)\n",
    "sessions = adk_app.list_sessions(user_id=user)\n",
    "session_id = sessions[\"sessions\"][0][\"id\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5593c8c2-ca85-4747-936c-4f1adaa970db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in adk_app.stream_query(\n",
    "        user_id=user,\n",
    "        session_id=session_id,\n",
    "        message=info_text,\n",
    "    ):\n",
    "        parts = event.get(\"content\", {}).get(\"parts\", []) if isinstance(event, dict) else []\n",
    "        text = parts[0].get(\"text\") if parts and isinstance(parts[0], dict) else None\n",
    "\n",
    "        if text and isinstance(text, str) and text.strip():\n",
    "            # Choose COMPLETE label\n",
    "            if last_start_idx_printed in COMPLETE_AFTER_START:\n",
    "                c_idx = COMPLETE_AFTER_START[last_start_idx_printed]\n",
    "            else:\n",
    "                c_idx = min(complete_idx, len(MESSAGES_COMPLETE) - 1)\n",
    "\n",
    "            # Only print if we haven’t already passed the last COMPLETE\n",
    "            if complete_idx < len(MESSAGES_COMPLETE):\n",
    "                log_area.markdown(MESSAGES_COMPLETE[c_idx])\n",
    "                with log_area.expander(f\"Model output (step {c_idx + 1})\", expanded=False):\n",
    "                    st.write(text)\n",
    "\n",
    "            complete_idx = max(complete_idx, c_idx) + 1\n",
    "            still_working_logged = False\n",
    "\n",
    "            # Advance START unless we’re at the last one\n",
    "            if (last_start_idx_printed or 0) + 1 < len(MESSAGES_START):\n",
    "                start_idx = last_start_idx_printed + 1\n",
    "                log_area.markdown(MESSAGES_START[start_idx])                \n",
    "                last_start_idx_printed = start_idx\n",
    "\n",
    "        else:\n",
    "            if not still_working_logged:\n",
    "                log_area.write(\"Still working..\")\n",
    "                still_working_logged = True\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m132",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m132"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
